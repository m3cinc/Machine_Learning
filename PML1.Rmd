---
title: "Practical Machine Learning: PML1"
author: "MB"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 9
    fig_height: 6
    fig_caption: yes
---
```{r global_options, include=FALSE,cache=TRUE}
knitr::opts_chunk$set(fig.width=9, fig.height=6.0, warning=FALSE, message=FALSE) 
```

### Summary

Accelerometer data provided as a pml.testing dataset (19622 observations) collected by 6 participants in belt, forearm, arm and dumbbell were analyzed and used to train a practical machine learning to predict a set of 20 outcomes (pml.testing) randomly sampled. From the available testing set, 12 variables corresponding to the accelerometer raw data were retained in each location in addition to the dependent outcome variable classe, (49 variables) were selected to train machine learning. 3 different algorithms were probed and evaluated based on their prediction accuracy (RPart, Random Forest and Gradient Boosting with trees), and available in the caret package. The most accurate prediction (>99.3%) were obtained with the Random Forest algorithm yielding to perfect scoring on the 20 random outcome. The only drawback encountered in this process was the compute time which on the Win64 platform took up to 7 hours to complete.

### System and platform documentation

Before any analysis is performed, let's start with system and platform documentation in a fresh directory to insure reproducibility.

```{r system ,cache=TRUE}
Sys.info()[1:5]                         # system info but exclude login and user info
userdir<-getwd()                        # user-defined startup directory
library(plyr)
library(dplyr)                          # provides data manipulating functions
library(ggplot2)                        # for graphics
library(GGally)
library(caret)
library(rpart)
library(rattle)
sessionInfo()                           # to document platform
```

### Loading and pre-processing

We implemented this project with and used r cache=TRUE as some large computation time were expected.
*It must noted that the download implemented here is using a non-secured link, i.e. with reduced confidence compared to a secured https protocol. However, knittr will encounter an error when attempting to download a binary (.zip) file with an https.protocol. Changing to a non-secured http url and setting file.download="wb" allows knittr to progress. This is strictly observed when knitting and the following error message is generated:*

*Error in download.file(url, dest = filename, mode = "wb") : unsupported URL scheme*

*Note also that R studio can handle https on the same binary file without error.*

The data files are uploaded directly in the /data subdirectory with non-secured http protocol from the corresponding urls and populate the data frames pml.training and pml.tetsing.

```{r data ,cache=TRUE}
datadir<-"./data" ; if (!file.exists("data")) { dir.create("data") } # data will reside in subdir 
url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
filename <- paste(datadir,strsplit(url,"/")[[1]][length(strsplit(url,"/")[[1]])],sep="/")
download.file(url, dest=filename, mode="wb")
pml.training <- read.csv(filename,header=TRUE,stringsAsFactors=FALSE)       # populate data frame 
url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename <- paste(datadir,strsplit(url,"/")[[1]][length(strsplit(url,"/")[[1]])],sep="/")
download.file(url, dest=filename, mode="wb")
pml.testing <- read.csv(filename,header=TRUE,stringsAsFactors=FALSE)       # populate data frame 
```

### Supporting Function

To ease submittal of trained answers, we include the function to populate answers as a character vector with 20 elements provided.

```{r writer ,cache=TRUE}
pml_write_files = function(x,y){
        n = length(x)
        for(i in 1:n){
                filename = paste0("problem_id_",i,".txt")
                filename = paste(outdir,filename,sep="/")
                write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
        }
}

```

### Initial Data Trimming and Plotting

We perform all trimming on copies of the dataframes dftrain and will perform similar trimming in dftest. Since all information is originally contained only in the raw data and we observe the stats data (min, max, total ,kurtosis, skewness, avg, std, var and amplitude) are mostly absent, we retain only the 12 raw-data variables (roll, pitch, yaw, (x,y,z)gyros, (x,y,z)accel and (x,y,z)magnet) for each location (belt, arm, dumbell and forearm) and the classe outcome. We also exclude the index X, user_name, and timestamping and window variables. This data trimming is performed systematically, using grep, as detailed:

```{r trimming ,cache=TRUE}
dftrain<-pml.training
flag<-NULL
flag<-c(flag,grep("^max",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^min",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^total",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^kurtosis",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^skewness",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^avg",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^stddev",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^var",colnames(dftrain),value=TRUE))
flag<-c(flag,grep("^amplitude",colnames(dftrain),value=TRUE))
dftrain<-dftrain[, !(names(dftrain) %in% flag)]
dftrain$classe<-as.factor(dftrain$classe)
dftrain$user_name<-as.factor(dftrain$user_name)
g0<-qplot(data=dftrain,X,classe,colour=user_name)
```

In order to visualize this data we simply chart...

```{r visual1, fig.width=9 ,fig.height=6, fig.cap="Fig1. Data sampling",cache=TRUE,echo=FALSE}
g0
```
```{r complete_trim ,cache=TRUE}
2*sum(dftrain$X)/nrow(dftrain)  # no info in X except line #, so can skip in model
M <- abs(cor(dftrain[,c(-1,-2,-3,-4,-5,-6,-56)]))
diag(M) <- 0
which(M > 0.8,arr.ind=T) # these variables appear not too correlated
keep<-row.names(M);keep=c("user_name",keep,"classe")
dftrain<-dftrain[,(names(dftrain)) %in% keep]
dftrain<-dftrain[,-c(1,2)] # do not retain user_name nor num_window for training
```

Now transform the test data set similarly than the training set...

```{r test_trim,cache=TRUE}
dftest<-pml.testing
dftest<-dftest[, !(names(dftest) %in% flag)]
dftest$user_name<-as.factor(dftest$user_name)
keep<-keep[c(-1,-2,-51)] # note we do not have classe in the testing set
dftest<-dftest[,(names(dftest)) %in% keep]
```

### Generating Plots

```{r plots ,cache=TRUE}
g1<-ggpairs(dftrain[,c( 1:12,49)],title="Belt Sensor Data",lower=list(continuous="smooth"),params=c(method="loess"),upper=list(params=list(corSize=6)),axisLabels='show')
g2<-ggpairs(dftrain[,c(13:24,49)],title="Arm Sensor Data",lower=list(continuous="smooth"),params=c(method="loess"),upper=list(params=list(corSize=6)),axisLabels='show')
g3<-ggpairs(dftrain[,c(25:36,49)],title="Dumbell Sensor Data",lower=list(continuous="smooth"),params=c(method="loess"),upper=list(params=list(corSize=6)),axisLabels='show')
g4<-ggpairs(dftrain[,c(37:48,49)],title="Forearm Sensor Data",lower=list(continuous="smooth"),params=c(method="loess"),upper=list(params=list(corSize=6)),axisLabels='show')
```

We illustrate for the Belt location... Other locations yield similar patterns.

```{r visual2, fig.width=9, fig.height=6, fig.cap="Fig.2 Belt sensor Data Pairwise Analysis",cache=TRUE,echo=FALSE}
g1
```

### Training

After setting seed (to enable reproducible outcome), start Machine training and perform sequentially 3 models (RPart, RF and GBM). The only pre-processing steps are to center and scale the data. The output is written to the respective subdirectories.

```{r train ,cache=TRUE}
set.seed(12321)
modelFit0 <- train(classe ~.,data=dftrain,preProcess=c("center","scale"),method="rpart")
modelFit0
print(modelFit0$finalModel)
```

Now let's display the tree...

```{r visual3, fig.width=9, fig.height=6, fig.cap="Fig 3. Rattle Output",cache=TRUE,echo=FALSE}
fancyRpartPlot(modelFit0$finalModel,sub = "")
```

And predict with ModelFit0, output predicted values to outdir...

```{r predict_RPart, cache=TRUE}
pred0<-predict(modelFit0,dftest);
outdir<-"./RPart_output";if (!file.exists("RPart_output")) { dir.create("RPart_output") } # RPart_output will reside in subdir 
pml_write_files(pred0,outdir)
```

We observe this model is quick but accuracy is very low...with RPart method, so we try Random Forest method training...

```{r train_RF, cache=TRUE}
modelFit1 <- train(classe ~.,data=dftrain,preProcess=c("center","scale"),method="rf",verbose=TRUE)
modelFit1
print(modelFit1$finalModel)
```

We observe high accuracy (>99.26%) can be achieved but the process is relatively slow. We will do our prediction with ModelFit1 and save in the corresponding outdir.

```{r predict_RF, cache=TRUE}
pred1<-predict(modelFit1,dftest);
outdir<-"./RF_output";if (!file.exists("RF_output")) { dir.create("RF_output") } # RF_output will reside in subdir 
pml_write_files(pred1,outdir)
```

Noting RF is very accurate but slow, we also try gbm method, a bit faster.

```{r train_gbm,cache=TRUE}
modelFit2 <- train(classe ~.,data=dftrain,preProcess=c("center","scale"),method="gbm",verbose=FALSE)
modelFit2
print(modelFit2$finalModel)
```

We observe accuracy slightly about 96% so we predict with modelFit2 and save in corresponding outdir.

```{r predict_gbm,cache=TRUE}
pred2<-predict(modelFit2,dftest);
outdir<-"./GBM_output";if (!file.exists("GBM_output")) { dir.create("GBM_output") } # GBM_output will reside in subdir
pml_write_files(pred2,outdir)
```

## Model Performance

The best accuracy is observed for the Random Forest algorithm, in excess of 99.2%.
We simply indicate output here and predictions, which scored 20/20! To quantify cross-validation errors, we will now repeat 3 times RF and average the accuracy to estimate the errors:

```{r cross-validate ,cache=TRUE}
Results<-data.frame()
Results<-modelFit1$results$Accuracy
modelFit1A <- train(classe ~.,data=dftrain,preProcess=c("center","scale"),method="rf",verbose=TRUE)
modelFit1A;print(modelFit1A$finalModel);pred1A<-predict(modelFit1A,dftest);
Results<-c(Results,modelFit1A$results$Accuracy)
modelFit1B <- train(classe ~.,data=dftrain,preProcess=c("center","scale"),method="rf",verbose=TRUE)
modelFit1B;print(modelFit1B$finalModel);pred1B<-predict(modelFit1B,dftest);
Results<-c(Results,modelFit1B$results$Accuracy)
summary(Results)
var(Results)
```

The predictions from these RF trained sets are:

```{r predict,cache=TRUE}
modelFit1
pred1;pred1A;pred1B
```

## Conclusions

This machine learning example shows potential of the RF algorithm, to predict activity from learned sensor data with exceptional accuracy, but also required heavy CPU time.

### References

1. Wearable Computing Accelerometer's Data Classification of Body Postures and Movements (Wallace Ugulino, et al, 08-22-2012 [link] (http://groupware.les.inf.puc-rio.br/har)
2. Coursera. Practical Machine Learning [link] (https://www.coursera.org/course/predmachlearn) part of Data Science Specialization Track [link] (https://www.coursera.org/specialization/jhudatascience/1?utm_medium=courseDescripTop)
